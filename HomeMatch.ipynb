{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f84176",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install --upgrade transformers\n",
    "!pip install diffusers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89290e6c",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Setup and Installation](#SETUP)\n",
    "2. [LLM Prompt and Listing Generation](#LLM)\n",
    "3. [Writing Listings to Database](#CHROMA-DB)\n",
    "4. [Getting Buyer Profile](#PROFILE)\n",
    "5. [Generate Personalized Listings](#P-LISTINGS)\n",
    "6. [Image Search with CLIP](#CLIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac305ba",
   "metadata": {},
   "source": [
    "## Setup and Installation <a id='SETUP'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6554fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79768e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"  \"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28acb1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain/llms/openai.py:202: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/langchain/llms/openai.py:790: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236235ca1a58479f886dadb5742bde14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205b155aee2f4893a85e7584c1bef9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f108146d138e47cb95ff33c3e3696c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639377e1810643a2b0f7bdfe087022f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae47c7089e6a4f9085002914b520635e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/862k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cfc8ad7357b42799feca43e957bd83c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea70ba10c0104e37ad2f83a09a683cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d321b1507de7461a86c5ace89f839e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Initializing the required models\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.8)\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "##sd_pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b520f67a",
   "metadata": {},
   "source": [
    "## LLM Prompt and Listing Generation <a id='LLM'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e37c6341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_listings(llm, prompt_template, n=10):\n",
    "    return [llm(prompt_template).strip() for _ in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16d44dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a helpful real estate assistant.\n",
    "\n",
    "Please generate a realistic real estate listing in the following format:\n",
    "Neighborhood: <neighborhood name>\n",
    "Price: <$xxx,xxx>\n",
    "Bedrooms: <int>\n",
    "Bathrooms: <int>\n",
    "House Size: <sqft>\n",
    "\n",
    "Description: <A paragraph with vivid and enticing details about the house>\n",
    "\n",
    "Neighborhood Description: <A paragraph that describes the neighborhood and nearby amenities>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afbfc92",
   "metadata": {},
   "source": [
    "## Writing Listings to Database <a id='CHROMA-DB'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9141438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_listings_to_json(listings, filename=\"listings.json\"):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(listings, f, indent=2)\n",
    "\n",
    "def load_listings_from_json(filename=\"listings.json\"):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def write_to_chromadb(listings, embedding_model, persist_directory=\"chromadb\", collection_name=\"real_estate\"):\n",
    "    os.makedirs(persist_directory, exist_ok=True)\n",
    "    db = Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        collection_name=collection_name,\n",
    "        embedding_function=embedding_model\n",
    "    )\n",
    "    metadatas = [{\"id\": i} for i in range(len(listings))]\n",
    "    db.add_texts(listings, metadatas=metadatas)\n",
    "    db.persist()\n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd71a10",
   "metadata": {},
   "source": [
    "## Getting Buyer Profile <a id='PROFILE'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c51de4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_buyer_profile():\n",
    "    buyer_questions = [\n",
    "        \"How big do you want your house to be?\",\n",
    "        \"What are 3 most important things for you in choosing this property?\", \n",
    "        \"Which amenities would you like?\", \n",
    "        \"Which transportation options are important to you?\",\n",
    "        \"How urban do you want your neighborhood to be?\",  \n",
    "    ]\n",
    "    answers = [input(q + \" \") for q in buyer_questions]\n",
    "    return \" \".join(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ff7ba9",
   "metadata": {},
   "source": [
    "## Generate Personalized Listings <a id='P-LISTINGS'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0e2fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def personalize_listings(llm, db, buyer_profile, k=3):\n",
    "    results = db.similarity_search(buyer_profile, k=k)\n",
    "    personalized = []\n",
    "    for res in results:\n",
    "        prompt = f\"\"\"\n",
    "You are a helpful real estate assistant.\n",
    "\n",
    "Buyer's Preferences:\n",
    "{buyer_profile}\n",
    "\n",
    "Original Listing:\n",
    "{res.page_content}\n",
    "\n",
    "Please rewrite the listing description and neighborhood description to subtly emphasize aspects aligned with the buyer's preferences, without changing facts.\n",
    "\"\"\"\n",
    "        personalized.append(llm(prompt).strip())\n",
    "    return personalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c398829",
   "metadata": {},
   "source": [
    "## Image Search with CLIP <a id='CLIP'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bfa70eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_matching_image(buyer_profile, image_folder=\"images\"):\n",
    "    clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    \n",
    "    image_paths = [os.path.join(image_folder, fname) for fname in os.listdir(image_folder) if fname.endswith(\".jpg\")]\n",
    "    \n",
    "    image_embeddings = []\n",
    "    for img_path in image_paths:\n",
    "        image = Image.open(img_path)\n",
    "        inputs = clip_processor(images=image, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            image_emb = clip_model.get_image_features(**inputs)\n",
    "            image_embeddings.append((img_path, image_emb))\n",
    "\n",
    "    text_inputs = clip_processor(text=buyer_profile, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        text_embedding = clip_model.get_text_features(**text_inputs)\n",
    "\n",
    "    similarities = [(path, torch.nn.functional.cosine_similarity(text_embedding, img_emb).item())\n",
    "                    for path, img_emb in image_embeddings]\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    top_image_path = similarities[0][0] if similarities else None\n",
    "    print(\"\\n Top Matching Image:\", top_image_path)\n",
    "    return top_image_path\n",
    "\n",
    "def save_personalized_listings(personalized, filename=\"personalized_listings.txt\"):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for i, listing in enumerate(personalized):\n",
    "            f.write(f\"\\n=== Personalized Listing {i+1} ===\\n{listing}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae720eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
